{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@387ebf61"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이벤트 시간과 상태 기반 처리 \n",
    "+ 이벤트 시간 처리 \n",
    "    + 이벤트 시간 : 데이터에 기록된 시간 기준 처리 \n",
    "    + 처리 시간 : 스트림 처리 시스템이 데이터를 실제로 수신한 시간 \n",
    "+ 상태 기반 처리 \n",
    "    + 중간 처리 정보를 사용하거나 갱신하는 경우에 필요(마이크로 배치 혹은 레코드 단위 처리) \n",
    "    + 스파크는 상태 저장소를 제공 \n",
    "+ 임의적인 상태 기반 처리 \n",
    "    + 상태의 유형, 갱신 방법, 제거 시점에 따라 세밀한 제어가 필요한 경우 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.4 이벤트 시간 처리의 기본  \n",
    "+ Creation_Time: 이벤트가 생성된 시간 \n",
    "+ Arrival_Time: 서버에 도착한 시간 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Arrival_Time: long (nullable = true)\n",
      " |-- Creation_Time: long (nullable = true)\n",
      " |-- Device: string (nullable = true)\n",
      " |-- Index: long (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- gt: string (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "activeDataPath = ../BookSamples/data/activity-data\n",
       "static = [Arrival_Time: bigint, Creation_Time: bigint ... 8 more fields]\n",
       "streaming = [Arrival_Time: bigint, Creation_Time: bigint ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[Arrival_Time: bigint, Creation_Time: bigint ... 8 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5) \n",
    "\n",
    "val activeDataPath = \"../BookSamples/data/activity-data\"\n",
    "val static = spark.read.json(activeDataPath) \n",
    "val streaming = spark.readStream.schema(static.schema).option(\"maxFilesPerTrigger\", 10).json(activeDataPath) \n",
    "\n",
    "static.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.5 이벤트 시간 윈도우 \n",
    "+ 나노세컨드 단위의 유닉스 시간으로 표현됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "withEventTime = [Arrival_Time: bigint, Creation_Time: bigint ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[Arrival_Time: bigint, Creation_Time: bigint ... 9 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val withEventTime = streaming.selectExpr(\"*\", \"cast(cast(Creation_Time as double)/1000000000 as timestamp) as event_time\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22.5.1 텀블링 윈도우 \n",
    "+ 디버깅 목적으로 결과를 메모리 싱크에 저장함 \n",
    "+ 스트림 처리가 시작되면 SQL로 결과 조회가 가능함 \n",
    "+ windows 컬럼은 struct 타입이며 윈도우 시작과 종료를 의미함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "active = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@4b2c47d2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@4b2c47d2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{window, col} \n",
    "\n",
    "val active = withEventTime.groupBy(window(col(\"event_time\"), \"10 minutes\"))\n",
    "    .count() \n",
    "    .writeStream\n",
    "    .queryName(\"events_per_windows\") \n",
    "    .format(\"memory\") \n",
    "    .outputMode(\"complete\") \n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@4b2c47d2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              window|count|\n",
      "+--------------------+-----+\n",
      "|[2015-02-23 10:40...|10973|\n",
      "|[2015-02-24 11:50...|18844|\n",
      "|[2015-02-24 13:00...|16621|\n",
      "|[2015-02-23 13:20...|13319|\n",
      "|[2015-02-22 00:40...|    1|\n",
      "|[2015-02-23 12:30...|12658|\n",
      "|[2015-02-24 11:20...|14225|\n",
      "|[2015-02-23 10:20...|12395|\n",
      "|[2015-02-24 12:20...|16648|\n",
      "|[2015-02-24 14:00...|18740|\n",
      "|[2015-02-24 12:30...|15773|\n",
      "|[2015-02-24 13:10...|13182|\n",
      "|[2015-02-24 14:10...|21174|\n",
      "|[2015-02-23 10:30...|12493|\n",
      "|[2015-02-24 13:40...|16501|\n",
      "|[2015-02-24 13:50...|12001|\n",
      "|[2015-02-23 14:30...|11854|\n",
      "|[2015-02-23 12:20...|13294|\n",
      "|[2015-02-23 13:40...|20836|\n",
      "|[2015-02-23 11:20...| 9408|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from events_per_windows\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "active.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 슬라이딩 윈도우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "active = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@c81bbd0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@c81bbd0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{window, col} \n",
    "\n",
    "val active = withEventTime.groupBy(window(col(\"event_time\"), \"10 minutes\", \"5 minutes\")) \n",
    "    .count() \n",
    "    .writeStream \n",
    "    .queryName(\"events_per_windows\") \n",
    "    .format(\"memory\") \n",
    "    .outputMode(\"complete\") \n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------+\n",
      "|window                                    |count |\n",
      "+------------------------------------------+------+\n",
      "|[2015-02-23 14:15:00, 2015-02-23 14:25:00]|107668|\n",
      "|[2015-02-24 11:50:00, 2015-02-24 12:00:00]|150773|\n",
      "|[2015-02-24 13:00:00, 2015-02-24 13:10:00]|133323|\n",
      "|[2015-02-22 00:35:00, 2015-02-22 00:45:00]|35    |\n",
      "|[2015-02-23 12:30:00, 2015-02-23 12:40:00]|100853|\n",
      "|[2015-02-23 10:20:00, 2015-02-23 10:30:00]|99178 |\n",
      "|[2015-02-23 13:25:00, 2015-02-23 13:35:00]|91684 |\n",
      "|[2015-02-24 14:25:00, 2015-02-24 14:35:00]|203945|\n",
      "|[2015-02-23 12:55:00, 2015-02-23 13:05:00]|113953|\n",
      "|[2015-02-22 00:40:00, 2015-02-22 00:50:00]|35    |\n",
      "|[2015-02-23 12:35:00, 2015-02-23 12:45:00]|91221 |\n",
      "|[2015-02-23 13:05:00, 2015-02-23 13:15:00]|205912|\n",
      "|[2015-02-24 11:20:00, 2015-02-24 11:30:00]|113768|\n",
      "|[2015-02-24 13:35:00, 2015-02-24 13:45:00]|174863|\n",
      "|[2015-02-24 14:00:00, 2015-02-24 14:10:00]|150225|\n",
      "|[2015-02-24 12:30:00, 2015-02-24 12:40:00]|125679|\n",
      "|[2015-02-24 13:10:00, 2015-02-24 13:20:00]|105494|\n",
      "|[2015-02-23 10:30:00, 2015-02-23 10:40:00]|100443|\n",
      "|[2015-02-24 11:45:00, 2015-02-24 11:55:00]|138413|\n",
      "|[2015-02-23 10:40:00, 2015-02-23 10:50:00]|88681 |\n",
      "+------------------------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from events_per_windows\").show(20, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "active.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22.5.2 워터마크로 지연 데이터 제어하기 \n",
    "+ 얼마나 늦게 도착한 데이터까지 받아들일지 기준을 정하지 않았기 때문에 중간 결과 데이터를 영원히 저장하는 문제가 있음 \n",
    "+ 오래된 데이터를 제거하는 데 필요한 워터마크를 반드시 지정해야 함 \n",
    "+ 최대 5시간까지 데이터가 지연된다면? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "active = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@318f7c0d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@318f7c0d"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val active = withEventTime \n",
    "    .withWatermark(\"event_time\", \"5 hours\") \n",
    "    .groupBy(window(col(\"event_time\"), \"10 minutes\", \"5 minutes\")) \n",
    "    .count() \n",
    "    .writeStream\n",
    "    .queryName(\"events_per_windows\") \n",
    "    .format(\"memory\") \n",
    "    .outputMode(\"complete\") \n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "active.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.6 스트림에서 중복 데이터 제거하기 \n",
    "+ 상태 정보가 무한히 커지지 않도록 워터마크를 명시해야 함 \n",
    "+ 예제에서는 중복 이벤트가 같은 식별자와 타임스탬프를 가진다고 가정함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "active = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@4fac9781\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@4fac9781"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val active = withEventTime\n",
    "    .withWatermark(\"event_time\", \"5 hours\") \n",
    "    .dropDuplicates(\"User\", \"event_time\") \n",
    "    .groupBy(window(col(\"event_time\"), \"10 minutes\", \"5 minutes\")) \n",
    "    .count() \n",
    "    .writeStream \n",
    "    .queryName(\"events_per_windows\") \n",
    "    .format(\"memory\") \n",
    "    .outputMode(\"complete\") \n",
    "    .start() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|[2015-02-23 14:15:00, 2015-02-23 14:25:00]|13484|\n",
      "|[2015-02-24 11:50:00, 2015-02-24 12:00:00]|37799|\n",
      "|[2015-02-24 13:00:00, 2015-02-24 13:10:00]|33383|\n",
      "|[2015-02-22 00:35:00, 2015-02-22 00:45:00]|1    |\n",
      "|[2015-02-23 12:30:00, 2015-02-23 12:40:00]|12658|\n",
      "|[2015-02-23 10:20:00, 2015-02-23 10:30:00]|12395|\n",
      "|[2015-02-23 13:25:00, 2015-02-23 13:35:00]|11441|\n",
      "|[2015-02-24 14:25:00, 2015-02-24 14:35:00]|50960|\n",
      "|[2015-02-23 12:55:00, 2015-02-23 13:05:00]|14172|\n",
      "|[2015-02-22 00:40:00, 2015-02-22 00:50:00]|1    |\n",
      "|[2015-02-23 12:35:00, 2015-02-23 12:45:00]|11424|\n",
      "|[2015-02-23 13:05:00, 2015-02-23 13:15:00]|25731|\n",
      "|[2015-02-24 11:20:00, 2015-02-24 11:30:00]|28394|\n",
      "|[2015-02-24 13:35:00, 2015-02-24 13:45:00]|43672|\n",
      "|[2015-02-24 14:00:00, 2015-02-24 14:10:00]|37491|\n",
      "|[2015-02-24 12:30:00, 2015-02-24 12:40:00]|31366|\n",
      "|[2015-02-24 13:10:00, 2015-02-24 13:20:00]|26306|\n",
      "|[2015-02-23 10:30:00, 2015-02-23 10:40:00]|12493|\n",
      "|[2015-02-24 11:45:00, 2015-02-24 11:55:00]|34469|\n",
      "|[2015-02-23 10:40:00, 2015-02-23 10:50:00]|10973|\n",
      "+------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from events_per_windows\").show(20, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "active.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.7 임의적인 상태 기반 처리\n",
    "+ 다음과 같은 처리 가능\n",
    "    + 특정 키의 개수를 기반으로 윈도우 생성\n",
    "    + 특성 시간 범위 안에 일정 개수 이상의 이벤트가 있는 경우 알림 발생시키기\n",
    "    + 결정되지 않은 시간 동안 사용자 세션을 유지하고 향후 분석을 위해 세션 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 두 가지의 유형\n",
    "    + mapGroupsWithState API : 최대 한 개의 로우를 만듬\n",
    "    + flatMapGroupsWithState API : 하나 이상의 로우를 만듬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22.7.1 타임아웃\n",
    "+ 타임 아웃은 전체 그룹에 대한 전역 파라미터로 동작함\n",
    "+ 타임아웃은 처리 시간(GroupStateTimeout.ProcessingTimeTimeout)이나 이벤트 시간(GroupStateTimeout.EventTimeTimeout) 중 하나가 될 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
