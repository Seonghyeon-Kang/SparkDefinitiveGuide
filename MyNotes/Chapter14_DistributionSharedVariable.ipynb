{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. 분산형 공유 변수\n",
    "+ 브로드캐스트 변수와 어큐뮬레이터라는 두 개의 타입이 존재\n",
    "    + 어큐뮬레이터: 모든 태스크의 데이터를 공유 결과에 추가할 수 있음\n",
    "    + 브로드캐스트: 모든 워커 노드에 큰 값을 저장하므로 재전송 없이 많은 스파크 액션에서 재사용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1 브로드캐스트 변수\n",
    "+ 변하지 않는 값(불변성 값)을 클로저 함수의 변수로 캡슐화하지 않고 클러스터에 효율적으로 공유\n",
    "    + 클로저의 개념: https://poiemaweb.com/js-closure\n",
    "    \n",
    "+ 브로드캐스트 변수는 모든 태스크마다 직렬화하지 않고 클러스터의 모든 머신에 캐시하는 불변성 공유 변수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_collection = 'Spark The Definitive Guide : Big Data Processing Made Simple'.split(\" \")\n",
    "words = spark.sparkContext.parallelize(my_collection, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplementalData = {\"Spark\":1000, \"Definitive\":200, \"Big\":-300, \"Simple\":100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ value 메서드를 사용해 값 참조\n",
    "\n",
    "+ 직렬화된 함수에서 브로드캐스트된 데이터를 직렬화하지 않아도 접근 가능\n",
    "    + 직렬화(자바): http://woowabros.github.io/experience/2017/10/17/java-serialize.html\n",
    "    + 직렬화(스파크): https://12bme.tistory.com/436\n",
    "    \n",
    "+ 브로드캐스트 변수는 모든 태스트마다 직렬화하지 않고 클러스터의 모든 머신에 캐시하는 불변성 공유 변수임\n",
    "    + 직렬화와 역직렬화에 대한 부하를 크게 줄일 수 있음\n",
    "    + 큰 크기의 데이터를 사용하는 경우 효과가 커짐\n",
    "    + UDF나 Dataset에서도 사용할 수 있으며 동일한 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppBroadcast = spark.sparkContext.broadcast(supplementalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Spark': 1000, 'Definitive': 200, 'Big': -300, 'Simple': 100}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suppBroadcast.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Big', -300),\n",
       " ('The', 0),\n",
       " ('Guide', 0),\n",
       " (':', 0),\n",
       " ('Data', 0),\n",
       " ('Processing', 0),\n",
       " ('Made', 0),\n",
       " ('Simple', 100),\n",
       " ('Definitive', 200),\n",
       " ('Spark', 1000)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suppBroadcast.value.get(word, 0) : dict의 get 함수 사용(있으면 word, 없으면 기본값 0)\n",
    "# sortBy(lambda wordPair: wordPair[1]) : 튜플의 2번째 값 기준으로 정렬\n",
    "words.map(lambda word: (word, suppBroadcast.value.get(word, 0)))\\\n",
    "    .sortBy(lambda wordPair: wordPair[1])\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2 어큐뮬레이터\n",
    "+ 트랜스포메이션 내부의 다양한 값을 갱신하는데 사용됨\n",
    "    + 디버깅용이나 저수준 집계 생성용으로 사용 가능\n",
    "    \n",
    "+ 어큐뮬레이터 값은 액션을 처리하는 과정에서만 갱신됨\n",
    "    + 각 태스크에서 어큐뮬레이터를 한 번만 갱신하도록 제어\n",
    "    + 따라서 재시작한 태스크는 어큐뮬레이터 값을 갱신할 수 없음\n",
    "    \n",
    "+ 스파크의 지연 연산 모델에 영향을 주지 않음\n",
    "\n",
    "+ 이름이 지정된 어큐뮬레이터의 실행 결과는 스파크 UI에 표현됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "flights = spark.read.parquet('./data/flight-data/parquet/2010-summary.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no named accumulator\n",
    "accChina = spark.sparkContext.accumulator(0)\n",
    "\n",
    "# # make name\n",
    "# spark.sparkContext.register(accChina, \"China\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The easiest way has been using SparkContext\n",
    "def accChinaFunc(flight_row):\n",
    "    destination = flight_row[\"DEST_COUNTRY_NAME\"]\n",
    "    origin = flight_row[\"ORIGIN_COUNTRY_NAME\"]\n",
    "    if \"China\" in (destination, origin):\n",
    "        accChina.add(flight_row[\"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ foreach는 액션이며, 액션에서만 어큐뮬레이터의 실행을 보장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.foreach(lambda flight_row: accChinaFunc(flight_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accChina.value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|            China|      United States|  448|\n",
      "+-----------------+-------------------+-----+\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|              China|  505|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 증명\n",
    "from pyspark.sql.functions import col, column\n",
    "\n",
    "flights.where(col(\"DEST_COUNTRY_NAME\") == 'China').show()\n",
    "flights.where(col(\"ORIGIN_COUNTRY_NAME\") == 'China').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.2 사용자 정의 어큐뮬레이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 어큐뮬레이터를 직접 정의하려면 AccmulatorV2 클래스를 상속 받아야 함\n",
    "    + 파이썬은 AccumulatorParam을 상속받아야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.accumulators import AccumulatorParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvenAccumulator(AccumulatorParam):\n",
    "    def __init__(self, param=0):\n",
    "        self.num = param\n",
    "\n",
    "    def reset(self):\n",
    "        self.num = 0\n",
    "        \n",
    "    def add(self, intvalue):\n",
    "        if (intvalue%2 == 0):\n",
    "            self.num += intvalue\n",
    "            \n",
    "    def value(self):\n",
    "        return self.num\n",
    "    \n",
    "    def iszero(self):\n",
    "        return self.num == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newAcc = EvenAccumulator()\n",
    "newAcc.add(3)\n",
    "newAcc.add(2)\n",
    "newAcc.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "newAcc.reset()\n",
    "flights.foreach(lambda flight_row: newAcc.add(flight_row['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newAcc.value() # 다시 확인 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<b'DEST_COUNTRY_NAME'>\n",
      "Column<b'ORIGIN_COUNTRY_NAME'>\n",
      "Column<b'count'>\n"
     ]
    }
   ],
   "source": [
    "for f in flights:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
